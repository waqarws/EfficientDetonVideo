{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple Inference Script of EfficientDet-Pytorch\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "import torch\n",
    "#from torch.backends import cudnn\n",
    "\n",
    "from backbone import EfficientDetBackbone\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from efficientdet.utils import BBoxTransform, ClipBoxes\n",
    "from utils.utils import preprocess, invert_affine, postprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_coef = 0\n",
    "force_input_size = None  # set None to use default size\n",
    "img_path = '/Users/wsarguroh001/Documents/Videos/TownCentre/TownCentre3950.jpg'\n",
    "\n",
    "# replace this part with your project's anchor config\n",
    "anchor_ratios = [(1.0, 1.0), (1.4, 0.7), (0.7, 1.4)]\n",
    "anchor_scales = [2 ** 0, 2 ** (1.0 / 3.0), 2 ** (2.0 / 3.0)]\n",
    "\n",
    "threshold = 0.2\n",
    "iou_threshold = 0.2\n",
    "\n",
    "use_cuda = False\n",
    "use_float16 = False\n",
    "#cudnn.fastest = True\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "#obj_list = ['person']\n",
    "obj_list = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "            'fire hydrant', '', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "            'cow', 'elephant', 'bear', 'zebra', 'giraffe', '', 'backpack', 'umbrella', '', '', 'handbag', 'tie',\n",
    "            'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',\n",
    "            'skateboard', 'surfboard', 'tennis racket', 'bottle', '', 'wine glass', 'cup', 'fork', 'knife', 'spoon',\n",
    "            'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut',\n",
    "            'cake', 'chair', 'couch', 'potted plant', 'bed', '', 'dining table', '', '', 'toilet', '', 'tv',\n",
    "            'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',\n",
    "            'refrigerator', '', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',\n",
    "            'toothbrush']\n",
    "\n",
    "# tf bilinear interpolation is different from any other's, just make do\n",
    "input_sizes = [512, 640, 768, 896, 1024, 1280, 1280, 1536]\n",
    "input_size = input_sizes[compound_coef] if force_input_size is None else force_input_size\n",
    "ori_imgs, framed_imgs, framed_metas = preprocess(img_path, max_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    x = torch.stack([torch.from_numpy(fi).cuda() for fi in framed_imgs], 0)\n",
    "else:\n",
    "    x = torch.stack([torch.from_numpy(fi) for fi in framed_imgs], 0)\n",
    "\n",
    "x = x.to(torch.float32 if not use_float16 else torch.float16).permute(0, 3, 1, 2)\n",
    "\n",
    "model = EfficientDetBackbone(compound_coef=compound_coef, num_classes=len(obj_list),\n",
    "                             ratios=anchor_ratios, scales=anchor_scales)\n",
    "model.load_state_dict(torch.load(f'weights/efficientdet-d{compound_coef}.pth'))\n",
    "model.requires_grad_(False)\n",
    "model.eval()\n",
    "\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "if use_float16:\n",
    "    model = model.half()\n",
    "\n",
    "with torch.no_grad():\n",
    "    features, regression, classification, anchors = model(x)\n",
    "\n",
    "    regressBoxes = BBoxTransform()\n",
    "    clipBoxes = ClipBoxes()\n",
    "\n",
    "    out = postprocess(x,\n",
    "                      anchors, regression, classification,\n",
    "                      regressBoxes, clipBoxes,\n",
    "                      threshold, iou_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(preds, imgs, imshow=True, imwrite=False):\n",
    "    for i in range(len(imgs)):\n",
    "        if len(preds[i]['rois']) == 0:\n",
    "            continue\n",
    "\n",
    "        for j in range(len(preds[i]['rois'])):\n",
    "            (x1, y1, x2, y2) = preds[i]['rois'][j].astype(np.int)\n",
    "            \n",
    "            obj = obj_list[preds[i]['class_ids'][j]]\n",
    "            score = float(preds[i]['scores'][j])\n",
    "\n",
    "            if obj == 'person':\n",
    "                cv2.putText(imgs[i], '{}, {:.3f}'.format(obj, score),\n",
    "                            (x1, y1 + 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                            (255, 255, 0), 1)\n",
    "                cv2.rectangle(imgs[i], (x1, y1), (x2, y2), (255, 255, 0), 2)\n",
    "\n",
    "        if imshow:\n",
    "            cv2.imshow('img', imgs[i])\n",
    "            cv2.waitKey(0)\n",
    "\n",
    "        if imwrite:\n",
    "            cv2.imwrite(f'test/img_inferred_d{compound_coef}_this_repo_{i}.jpg', imgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = invert_affine(framed_metas, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(out, ori_imgs, imshow=False, imwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running speed test...\n",
      "test1: model inferring and postprocessing\n",
      "inferring image for 10 times...\n",
      "0.7449088096618652 seconds, 1.3424461988225482 FPS, @batch_size 1\n"
     ]
    }
   ],
   "source": [
    "print('running speed test...')\n",
    "with torch.no_grad():\n",
    "    print('test1: model inferring and postprocessing')\n",
    "    print('inferring image for 10 times...')\n",
    "    t1 = time.time()\n",
    "    for _ in range(10):\n",
    "        _, regression, classification, anchors = model(x)\n",
    "\n",
    "        out = postprocess(x,\n",
    "                          anchors, regression, classification,\n",
    "                          regressBoxes, clipBoxes,\n",
    "                          threshold, iou_threshold)\n",
    "        out = invert_affine(framed_metas, out)\n",
    "\n",
    "    t2 = time.time()\n",
    "    tact_time = (t2 - t1) / 10\n",
    "    print(f'{tact_time} seconds, {1 / tact_time} FPS, @batch_size 1')\n",
    "\n",
    "    # uncomment this if you want a extreme fps test\n",
    "    # print('test2: model inferring only')\n",
    "    # print('inferring images for batch_size 32 for 10 times...')\n",
    "    # t1 = time.time()\n",
    "    # x = torch.cat([x] * 32, 0)\n",
    "    # for _ in range(10):\n",
    "    #     _, regression, classification, anchors = model(x)\n",
    "    #\n",
    "    # t2 = time.time()\n",
    "    # tact_time = (t2 - t1) / 10\n",
    "    # print(f'{tact_time} seconds, {32 / tact_time} FPS, @batch_size 32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Efficient Det on Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c59c4edb3e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Videos/TownCentre'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Keep Video at root folder and create a folder named 'Videos' at root\n",
    "# Read Video File and Write Image Files\n",
    "\n",
    "cap = cv2.VideoCapture('TownCentreXVID.avi')\n",
    "\n",
    "i=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite('Videos/TownCentre'+str(i)+'.jpg',frame)\n",
    "    i+=1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def area_bbox(x1, y1, x2, y2):\n",
    "    return (x2 - x1)*(y2 - y1)\n",
    "\n",
    "def is_too_close(p1, p2):\n",
    "    x11, y11, x12, y12 = p1\n",
    "    x21, y21, x22, y22 = p2\n",
    "    #total_region_coords \n",
    "    X1 = min(x11, x21)\n",
    "    Y1 = min(y11, y21)\n",
    "    X2 = max(x12, x22)\n",
    "    Y2 = max(y12, y22)\n",
    "    \n",
    "    ratio = area_bbox(X1, Y1, X2, Y2)/sum([area_bbox(x11, y11, x12, y12), area_bbox(x21, y21, x22, y22)])\n",
    "    \n",
    "    if ratio<1.2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_out = {}\n",
    "new_out['rois'] = []\n",
    "new_out['scores'] = []\n",
    "for i in range(len(out[0]['rois'])):\n",
    "    if out[0]['class_ids'][i] == 0:\n",
    "        new_out['rois'].append(out[0]['rois'][i])\n",
    "        new_out['scores'].append(out[0]['scores'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_out['is_too_close'] = []\n",
    "for i in range(len(new_out['rois'])):\n",
    "    test = any([is_too_close(new_out['rois'][i], p) for p in new_out['rois'][:i] + new_out['rois'][i+1:]])\n",
    "    new_out['is_too_close'].append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_modified(new_out, img):\n",
    "    #for i in range(len(imgs)):\n",
    "    if len(new_out['rois']) == 0:\n",
    "        return 0\n",
    "\n",
    "    for j in range(len(new_out['rois'])):\n",
    "        (x1, y1, x2, y2) = new_out['rois'][j].astype(np.int)\n",
    "\n",
    "        if new_out['is_too_close'][j]:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imwrite('test.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_modified(new_out, ori_imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
